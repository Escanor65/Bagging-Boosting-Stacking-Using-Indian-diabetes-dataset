{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Bagged Decision Trees for Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfilename = '../input/prima123/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nseed = 7\n\nkfold = KFold(n_splits=10, random_state=seed)\ncart = DecisionTreeClassifier()\nnum_trees = 100\nmodel = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:41:21.575128Z","iopub.execute_input":"2021-11-24T06:41:21.575661Z","iopub.status.idle":"2021-11-24T06:41:27.173064Z","shell.execute_reply.started":"2021-11-24T06:41:21.575628Z","shell.execute_reply":"2021-11-24T06:41:27.172235Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Random Forest Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n\nX = array[:,0:8]\nY = array[:,8]\nnum_trees = 100\nmax_features = 3\nkfold = KFold(n_splits=10, random_state=7)\nmodel = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:41:27.174538Z","iopub.execute_input":"2021-11-24T06:41:27.174955Z","iopub.status.idle":"2021-11-24T06:41:29.995088Z","shell.execute_reply.started":"2021-11-24T06:41:27.174925Z","shell.execute_reply":"2021-11-24T06:41:29.994196Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# AdaBoost Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\nfilename = '../input/prima123/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename, names=names)\narray = dataframe.values\n\nX = array[:,0:8]\nY = array[:,8]\n\nnum_trees = 10\nseed=7\nkfold = KFold(n_splits=10, random_state=seed)\nmodel = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:41:29.996167Z","iopub.execute_input":"2021-11-24T06:41:29.996464Z","iopub.status.idle":"2021-11-24T06:41:30.274158Z","shell.execute_reply.started":"2021-11-24T06:41:29.996435Z","shell.execute_reply":"2021-11-24T06:41:30.273222Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Stacking Ensemble for Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfilename = '../input/prima123/pima-indians-diabetes.data.csv'\nnames = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\ndataframe = read_csv(filename, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nkfold = KFold(n_splits=10, random_state=7)\n\n# create the sub models\nestimators = []\nmodel1 = LogisticRegression(max_iter=500)\nestimators.append(('logistic', model1))\nmodel2 = DecisionTreeClassifier()\nestimators.append(('cart', model2))\nmodel3 = SVC()\nestimators.append(('svm', model3))\n\n# create the ensemble model\nensemble = VotingClassifier(estimators)\nresults = cross_val_score(ensemble, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"execution":{"iopub.status.busy":"2021-11-24T06:41:30.275434Z","iopub.execute_input":"2021-11-24T06:41:30.275729Z","iopub.status.idle":"2021-11-24T06:41:30.992633Z","shell.execute_reply.started":"2021-11-24T06:41:30.275701Z","shell.execute_reply":"2021-11-24T06:41:30.991605Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}